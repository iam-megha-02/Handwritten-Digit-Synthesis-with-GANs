# -*- coding: utf-8 -*-
"""LAB_06_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RddiU5df-IJgJ-BIsbTP1DooTkvrH_-W
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import glob
import cv2
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers
import matplotlib.pyplot as plt

project_dir = "/content/drive/MyDrive/Handwriting_GAN"
dataset_dir = "/content/drive/MyDrive/augmented_digits"
generated_images_dir = os.path.join(project_dir, "generated")
checkpoint_dir = os.path.join(project_dir, "checkpoints")

os.makedirs(generated_images_dir, exist_ok=True)
os.makedirs(checkpoint_dir, exist_ok=True)

print("Using dataset from:", dataset_dir)

def preprocess_image(path, size=(28,28)):
    img = Image.open(path).convert("L")
    img = img.resize(size)
    return np.array(img)

print("Loading images...")
files = glob.glob(os.path.join(dataset_dir, "*.png"))
images = [preprocess_image(f) for f in files]

X = np.array(images).astype("float32")
X = (X - 127.5) / 127.5
X = X.reshape(-1, 28, 28, 1)
print("Dataset shape:", X.shape)

BUFFER_SIZE = X.shape[0]
BATCH_SIZE = 64
dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

def make_generator_model():
    model = tf.keras.Sequential([
        layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),
        layers.BatchNormalization(),
        layers.LeakyReLU(),
        layers.Reshape((7,7,256)),
        layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False),
        layers.BatchNormalization(),
        layers.LeakyReLU(),
        layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False),
        layers.BatchNormalization(),
        layers.LeakyReLU(),
        layers.Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh')
    ])
    return model

def make_discriminator_model():
    model = tf.keras.Sequential([
        layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28,28,1]),
        layers.LeakyReLU(),
        layers.Dropout(0.3),
        layers.Conv2D(128, (5,5), strides=(2,2), padding='same'),
        layers.LeakyReLU(),
        layers.Dropout(0.3),
        layers.Flatten(),
        layers.Dense(1)
    ])
    return model

generator = make_generator_model()
discriminator = make_discriminator_model()

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
def discriminator_loss(real_output, fake_output):
    return cross_entropy(tf.ones_like(real_output), real_output) + cross_entropy(tf.zeros_like(fake_output), fake_output)
def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

EPOCHS = 10000
noise_dim = 100
num_examples_to_generate = 16
seed = tf.random.normal([num_examples_to_generate, noise_dim])

@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)
        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)
        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def generate_and_save_images(model, epoch, test_input):
    predictions = model(test_input, training=False)
    fig = plt.figure(figsize=(4,4))
    for i in range(predictions.shape[0]):
        plt.subplot(4,4,i+1)
        plt.imshow(predictions[i,:,:,0]*127.5 + 127.5, cmap='gray')
        plt.axis('off')
    file_path = f"{generated_images_dir}/epoch_{epoch}.png"
    plt.savefig(file_path)
    plt.show()
    print(f"Generated samples saved at {file_path}")

print("Starting training...")
for epoch in range(1, EPOCHS+1):
    for image_batch in dataset:
        train_step(image_batch)
    if epoch % 500 == 0:
        print(f"Epoch {epoch} completed")
        generate_and_save_images(generator, epoch, seed)
        checkpoint.save(file_prefix=checkpoint_prefix)

def display_original_vs_generated(generator, test_input, original_images):
    predictions = generator(test_input, training=False)

    fig, axes = plt.subplots(2, len(original_images), figsize=(15,4))

    # Row 1: Original images
    for i, img in enumerate(original_images):
        axes[0, i].imshow(img.reshape(28,28)*127.5 + 127.5, cmap='gray')
        axes[0, i].set_title(f"Original {i+1}")
        axes[0, i].axis('off')

    # Row 2: Generated images
    for i in range(len(predictions)):
        axes[1, i].imshow(predictions[i,:,:,0]*127.5 + 127.5, cmap='gray')
        axes[1, i].set_title(f"Generated {i+1}")
        axes[1, i].axis('off')

    plt.tight_layout()
    plt.show()

# Pick some of your original images (first 9)
num_show = min(9, len(X))
sample_originals = X[:num_show]

# Generate samples using trained generator
final_noise = tf.random.normal([num_show, noise_dim])
display_original_vs_generated(generator, final_noise, sample_originals)

